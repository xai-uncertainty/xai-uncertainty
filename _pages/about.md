---
layout: about
title: About
permalink: /
subtitle:
news: False  # includes a list of news items
latest_posts: False  # includes a list of the newest posts
selected_papers: False # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

<p align="center" style="font-weight:bold; font-size:30px"> Uncertainty meets Explainability | Workshop and Tutorial @
<a href="https://2023.ecmlpkdd.org/">ECML-PKDD 2023</a>
</p>

---

<p style="color:blue" align="center"> Click
<a href="https://cmt3.research.microsoft.com/ECMLPKDDworkshop2023/Track/3/Submission/Create">[here]</a>  to submit a paper or 
<a href="cfp">[here]</a> to read the CFP (New extension until 23 June 2023 (AoE))
</p>

---

<p style="color:blue" align="center"> 
<a href="mailto:xai.uncertainty@gmail.com">[Click here to submit any question to the organizers]</a></p>

---

Machine learning systems have become increasingly popular in crucial high-stakes fields, such as healthcare and finance. To be effective in these domains, the models must not only make precise predictions but also provide relevant explanations for those predictions. To achieve this goal, there has been a substantial research effort in recent years to develop techniques that explain black-box models and create models that are interpretable by design.

Simultaneously, there is a growing emphasis on machine learning models that account for uncertainty. Decision-making systems can encounter uncertainties stemming from different origins, each offering a distinct perspectives. For instance, aleatoric uncertainty arises from the inherent randomness of the prediction, while epistemic uncertainty from the insufficient amount of data. In general, incorporating uncertainty enhances a model's reliability by allowing it to acknowledge scenarios where it lacks the necessary knowledge to make an accurate prediction.

The intersection of explainability and uncertainty has drawn attention for its potential to combine these domains towards Trustworthy ML. Some notable innovative approaches include: developing interpretability methods for probabilistic models, quantifying the uncertainty of explanations, and explaining the sources of uncertainty.

The primary goal of this full-day event, consisting of a Tutorial and a Workshop, is to jointly explore how explainability and uncertainty can be leveraged to build robust and trustworthy AI systems. The tutorial (morning session) will establish the foundation for (a) uncertainty modeling and (b) explainability in machine learning. Then, the workshop (afternoon session) will delve into innovative techniques at the intersection of these two domains.

The workshop & tutorial will be an in-person event at [ECML-PKDD 2023](https://2023.ecmlpkdd.org/). The session will cover invited talks, contributed talks, posters, and a panel discussion.

---

### **Key Dates**

- Submission Deadline: **~~12 June 2023 (AoE)~~ ~~20 June 2023 (AoE)~~**
- Author Notification: **12 July 2023 (AoE)**
- Event Date: **22 September 2023**

---

### **Organizers**

- Workshop:
  - [Vasilis Gkolemis](https://givasile.github.io)
  - [Christos Diou](https://diou.github.io)

- Tutorial:
  - [Viktor Bengs](https://www.kiml.ifi.lmu.de/people/postdocs/bengs/index.html)
  - [Eyke Hullermeier](https://www.kiml.ifi.lmu.de/people/professors/huellermeier/index.html)
  - [Willem Waegeman](http://www.bioml.ugent.be/)

---

### **Program Committee** (TBU)

- [Albert Calvo (i2CAT)](https://scholar.google.es/citations?user=vm5Ki34AAAAJ)
- [Carlos Mougan (University of Southampton)](https://cmougan.github.io/)
- [Dimitrios Gunopulos (NKUA)](https://research.ibm.com/people/rahul-nair)
- [Dimitris Sacharidis (ULB)](https://www.ulb.be/fr/dimitris-sacharidis-1)
- [Dimitris Fotakis (NTUA)](https://www.ece.ntua.gr/en/staff/180)
- [Eirini Ntoutsi (UNIBW)](https://www.unibw.de/home-en/appointment-of-professors/prof-eirini-ntoutsi)
- [Giorgos Giannopoulos (ATHENA RC)](https://www.imsi.athenarc.gr/en/people/member/7)
- [Giorgos Papastefanatos (ATHENA RC)](https://www.imsi.athenarc.gr/en/people/member/40)
- [Guiseppe Casalicchio (LMU)](https://www.slds.stat.uni-muenchen.de/people/casalicchio/)
- [Hamid Bouchachia (Bournemouth University)](https://staffprofiles.bournemouth.ac.uk/display/abouchachia)
- [Helen Psaroudaki (NTUA)](https://www.linkedin.com/in/helen-psaroudaki-2454391a7/?originalSubdomain=gr)
- [Jakub Marecek (CVUT)](https://cs.felk.cvut.cz/en/people/marecjak)
- [Kostas Stefanidis (TUNI)](https://homepages.tuni.fi/konstantinos.stefanidis/)
- [Loukas Kavouras (ATHENA RC)](https://www.linkedin.com/in/loukas-kavouras-phd-4a6508123/?originalSubdomain=gr)
- [Maria Tzelepi (AUTH)](https://scholar.google.gr/citations?user=ZMOW1K0AAAAJ&hl=el)
- [Rahul Nair (IBM)](https://research.ibm.com/people/rahul-nair)
p- [Theodore Dalamagas (ATHENA RC)](https://www.imsi.athenarc.gr/en/people/member/4)
- [Theodora Tsikrika (CERTH)](https://scholar.google.com/citations?user=7LNLZXoAAAAJ&hl=en)


---

### **Organizations**

<a href="https://www.ugent.be/en"><img src="assets/img/ghent_logo.png" alt="Ghent logo" width="250"></a>
<a href="https://www.lmu.de/en/"><img src="assets/img/lmu_logo.png" alt="LMU logo" width="250"></a>
<a href="https://www.athenarc.gr/en"><img src="assets/img/athena_logo.jpg" alt="ATHENA logo" width="350"></a>
<a href="https://www.dit.hua.gr/index.php/el/"><img src="assets/img/harokopio.png" alt="Harokopio logo" width="500"></a>

---

### **Supported by**

<a href="https://ai4manufacturing.eu/"><img src="assets/img/logo_xmanai.png" alt="XMANAI logo" width="250"></a>
<a href="https://cordis.europa.eu/project/id/101070568"><img src="assets/img/logo_autofair.png" alt="ExtremeXP logo" width="250"></a>
<a href="https://extremexp.eu"><img src="assets/img/logo-extremexp.png" alt="ExtremeXP logo" width="250"></a>
<a href="https://www.releviumproject.eu/"><img src="assets/img/logo_relevium.png" alt="Revelium logo" width="250"></a>

---
